---
title: "Low Dimensionality"
author: "김태경"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{(Korean) Modeling Low Dimensionality}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

``Giovanni Gavetti'' and ``Daniel Levinthal'' published an interesting paper in the **Administrative Science Quarterly** in 2000. Titled ``Looking Forward and Looking Backward: Cognitive and Experimental Search'', this paper shows how to express the bounded rationality of ``Simon'' as an NK model. With ``rNKm'', the idea of ​​Gavetti & Levinthal (2000) can be used simply. This article introduces a method of implementing the proposed Low Dimensionality (LD) as a concrete practice method expressing limited rationality.




## Low Dimensionality

For more details, please refer to the *Fitness landscape and cognition* section in the paper of Gavetti & Levinthal (2000), and this tutorial briefly explains the concept.

1. Cognition is dependent on the expression method of landscape: The binary combination expressing the location of the landscape is the same as cognition.
1. Lower dimensionality reflects the true dimensional landscape
1. If the perceived dimension of an actor is N1, $N1<=N$
1. The cognitive representation that an actor will encounter in N1's cognitive space (ie, low dimensionality space) is reduced from $2^(N-N1)$ real landscape components.



Eventually, as N1 decreases, the reduction points increase, and the cognitive expression becomes extremely flat. This is like pushing some points with a bulldozer. For example, suppose that an actor's cognitive expression is '1 0 0 0'and this is the case when N=4. If the cognitive dimension reduced to N1 knows only the first and second elements and the rest are ignorant, it appears to have been erased as '1 0 * *'. N1=2 and the number of spaces to be reduced is determined by $2^(4-2)$. Now let's say that in order to reconstruct the reduced space, we take the method of calculating the average by considering the number of all cases. Going back, each element contributing to the reconstruction is '1 0 0 0', '1 0 1 0', '1 0 0 1', and '1 0 1 1'. Let's look at the meaning of becoming flat. One of the neighbors of the expression '1 0 0 0'(that is, only one element has changed)

It is '1 0 1 0'. Only the third factor is different. However, since it is the case of '1 0 * *', the third change is meaningless. In other words, the elements contributing to the reconstruction are '1 0 0 0', '1 0 1 0', '1 0 0 1'and '1 0 1 1'as in '1 0 0 0', so N1 is assumed. In the case of '1 0 0 0'or '1 0 1 0', there is no difference in the fitness value in the landscape. Therefore, in the case of a cognitive expression that does not correspond to N1, the neighbors change into a shape that replaces the fitness of the original landscape with an average value (in a metaphorical sense, pushed it by a bulldozer). In other words, any combination of factors is replaced by the popular perception of **not so**.

Community-verified icon


## Create Low Dimensionality parts

The key to rNKm's low dimensionality is to generate low-dimensional subsets using N1 markers. This is done through the ``gen_lowdim_fraction()'' function.



```{r, eval=TRUE}
require(rNKm)
#N1의 masking은 1번과 2번이므로 c(1,2)
#표현하려는 landscape의 agent의 위치는 c(1,0,0,0)이라면,
gen_lowdim_fraction(c(1,0,0,0),c(1,2))
```

And
```{r, eval=TRUE}
gen_lowdim_fraction(c(1,0,1,0),c(1,2))
```

## Creating a Landscape with Low Dimensionality

Based on the function ``gen_lowdim_fraction()'', the ``landscape_gen_lowdim()'' function creates a landscape expressing low dimensionality.


```{r,eval=TRUE}
fun <- landscape_gen_lowdim(N=4,K=1,N1=c(1,2))
fun(c(0,0,0,0))
fun(c(1,0,0,0))
fun(c(1,0,1,0))
fun(c(1,0,1,1))
```

In the example above, c(1,2) was given as the masking value of N1. This means that the agent only considers components 1 and 2 as targets of recognition, and in cases 3 and 4, it is governed by bounded rationality. Consider the case of specifying a random structure externally to compare the result with the true landscape.

The ``landscape_structure_uniform()'' function creates and returns a uniform distribution random number structure based on the given values ​​of N and K. If this is entered as a parameter g in ``landscape_gen()'' or ``landscape_gen_lowdim()'', the same random number structure is maintained. Of course, you can set a random seed in ``landscape_structure_uniform'' or set.seed() outside the function to set a random seed value. For a number of reasons I recommend the second method.



```{r, eval=TRUE}
set.seed(1) #random seed=1
rnd_str <- landscape_structure_uniform(N=4,K=1)
fun_full <- landscape_gen(N=4,K=1,g=rnd_str)
fun_ld <- landscape_gen_lowdim(N=4,K=1,N1=c(1,2),g=rnd_str)
```

The two cognitive expressions that an agent can take for ``fun_full()'' and ``fun_ld()'', 1 0 0 0 and 1 0 1 0, give different results. The fitness values ​​of fun_full() are different, but fun_ld() is in a flat landscape, so they are the same.



```{r, eval=TRUE}
fun_full(c(1,0,0,0))
fun_full(c(1,0,1,0))
fun_ld(c(1,0,0,0))
fun_ld(c(1,0,1,0))
```

Comparison of large and small goodness-of-fit values ​​is meaningless here. This is because the calculated fit is not standardized. The function that normalizes a real vector based on the maximum and minimum is ``scales::rescale()''. Using this function, all values ​​in a given vector are normalized between 0 and 1. For simulation purposes, it is wise to standardize the final result if you want to compare two or more cases.



```{r, eval=TRUE}
library(scales)
rnd_str
rescale(rnd_str)
```

## Peak 탐색 실험

![GL](gavetti_levinthal_2000.jpg)

The picture above is presented by **Gavetti & Levinthal** in *Administrative Science Quarterly* Volume 45 in 2000. Looking at the figure, it can be seen that when there is low dimensionality, the number of peaks is small. When modeling with {rNKm}, you can get results consistent with this.



![LDexp](lowdim_exp.png)
This is a picture of the average value of three repetitive simulations of landscape_gen_lowdim() set to N=6 and N1=2.
